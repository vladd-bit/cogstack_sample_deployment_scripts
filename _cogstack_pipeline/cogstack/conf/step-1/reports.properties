## ACTIVE SPRING PROFILES
##
spring.profiles.active = jdbc_in,elasticsearchRest,localPartitioning # ,tika

#### JOB REPO DB CONFIGURATIONS
##
jobRepository.JdbcPath = jdbc:postgresql://cogstack-job-repo:5432/cogstack_job_repo
jobRepository.Driver = org.postgresql.Driver
jobRepository.username = cogstack
jobRepository.password = cogstack

#### SOURCE: DB CONFIGURATIONS
##
source.JdbcPath = jdbc:postgresql://databank-db:5432/project_data
source.Driver = org.postgresql.Driver
source.username = admin
source.password = admin

# Type of the timestamp field: 'TIMESTAMP', 'DATETIME', 'DATE' or 'TIME'
source.dbmsToJavaSqlTimestampType = TIMESTAMP

#### SINK: POSTGRES TARGET DB CONFIGURATION
##
target.JdbcPath =  jdbc:postgresql://databank-db:5432/project_data
target.Driver = org.postgresql.Driver
target.username = admin
target.password = admin

### MORE Source Configs

# optional (default: 10): number of allocated connections to source DB (kept until the end of processing)
# source.poolSize = 10

# The principle SQL block that specifies data to process. Composed of three parts.
source.selectClause = SELECT *
source.fromClause = FROM observations_view
source.sortKey = subject_id

# The principle DB column label mapping for Document data model
source.primaryKeyFieldValue = subject_id
source.timeStamp = charttime

# Since different DBMS products interpret the SQL standard for time differently, is is necessary to explicitly specify
# the date type that the database is using. E.G. postgres=TIMESTAMP, SQL SERVER=DATETIME
source.dbmsToJavaSqlTimestampType = TIMESTAMP

#### PARTITIONER CONFIGURATION
##
## This is used to inform how the total row count per job should be broken into
## seperate partitions
##
# Two partitioner types are available, either using primary keys (PK) or timestamps and primary keys (PKTimeStamp)
# If using the scheduler, the PKTimeStamp type should be configured
partitioner.partitionType = PKTimeStamp

# optional (default: 1): number of partitions to generate (x / total job row count)
#partitioner.gridSize = 1

# name of timestamp column used for partitioning and checking for new data (only if scheduling is used)
partitioner.timeStampColumnName = charttime

# name of PK column used for partitioning and checking for new data
# only use with scheduling if PKs are guaranteed to be generated sequentially
partitioner.pkColumnName = subject_id

# this is the table containing the primary keys and optionally, timestamps
partitioner.tableToPartition = observations_view


##### SINK: ELASTICSEARCH CONFIGURATION
##
elasticsearch.cluster.host = elasticsearch-1
elasticsearch.cluster.port = 9200

#ES basic auth from X-pack security plugin (commercial)
# elasticsearch.security.enabled = false
## for Http auth
# elasticsearch.security.user = username_1
# elasticsearch.security.password = password_1
# elasticsearch.ssl.enabled = false

# ES indexing options -- in this example we will use multiple indices
elasticsearch.index.name = mimic_observations_view
elasticsearch.excludeFromIndexing = noteevent.text